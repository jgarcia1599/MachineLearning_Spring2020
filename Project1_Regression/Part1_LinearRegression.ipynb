{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Part1_LinearRegression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm8Xmtoy6TTL",
        "colab_type": "text"
      },
      "source": [
        "# Simple Linear versus Ridge Regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C6FopWK6TTP",
        "colab_type": "text"
      },
      "source": [
        "## Step 1:  Getting, understanding, and preprocessing the dataset\n",
        "\n",
        "We first import the standard libaries and some libraries that will help us scale the data and perform some \"feature engineering\" by transforming the data into $\\Phi_2({\\bf x})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBgHUpXx6TTQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "27f85444-13d3-4506-e409-02b5c9328946"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.linear_model\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8e8c1b9e1b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHEEXHAP6TTW",
        "colab_type": "text"
      },
      "source": [
        "###  Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "astUD2iD6TTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the boston dataset from sklearn\n",
        "# Load dataset to some variable \n",
        "# boston_data = ....."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwwrrMT46TTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Create X and Y variables - X holding the .data and Y holding .target \n",
        "# X = boston_data.....\n",
        "# y = boston_data.....\n",
        "\n",
        "#  Reshape Y to be a rank 2 matrix using y.reshape()\n",
        "\n",
        "# Observe the number of features and the number of labels\n",
        "# print('The number of features is: ', X.shape[1])\n",
        "# Printing out the features\n",
        "# print('The features: ', boston_data.feature_names)\n",
        "# The number of examples\n",
        "# print('The number of exampels in our dataset: ', X.shape[0])\n",
        "# Observing the first 2 rows of the data\n",
        "# print(X[0:2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrZz7zOS6TTd",
        "colab_type": "text"
      },
      "source": [
        "We will also create polynomial feeatures for the dataset to test linear and ridge regression on data with d = 1 and data with d = 2. Feel free to increase the # of degress and see what effect it has on the training and test error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "insP8v9S6TTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a PolynomialFeatures object with degree = 2. Using PolynomialFeatures(degree=2)\n",
        "# Transform X and save it into X_2 using poly.fit_transform(X)\n",
        "# Simply copy Y into Y_2 \n",
        "\n",
        "# X_2 = ....\n",
        "# y_2 = ...."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KmrkFYL6TTh",
        "colab_type": "code",
        "colab": {},
        "outputId": "10aaee4c-bde8-4052-d79b-8cabdb9c7e6e"
      },
      "source": [
        "# the shape of X_2 and Y_2 - should be (506, 105) and (506, 1) respectively\n",
        "print(X_2.shape)\n",
        "print(y_2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-65ca49a05891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# the shape of X_2 and Y_2 - should be (506, 105) and (506, 1) respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_DmMrRJ6TTk",
        "colab_type": "text"
      },
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xlPwti96TTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the get_coeff_ridge_normaleq function. Use the normal equation method.\n",
        "# Return w values\n",
        "\n",
        "def get_coeff_ridge_normaleq(X_train, y_train, alpha):\n",
        "    # use np.linalg.pinv(...)\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2sNK9yA6TTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the get_coeff_ridge_normaleq function. Use the normal equation method.\n",
        "# Return w values\n",
        "\n",
        "def get_coeff_linear_normaleq(X_train, y_train):\n",
        "    # use np.linalg.pinv(...)\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr5M4ATR6TTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the evaluate_err_ridge function.\n",
        "# Return the train_error and test_error values\n",
        "\n",
        "\n",
        "def evaluate_err(X_train, X_test, y_train, y_test, w): \n",
        "#     pred_train=prediction using w and X_tran+np.mean(y_train)\n",
        "#     pred_test=prediction using w and X_test\n",
        "#     remember to add the mean back\n",
        "#     train_error=...\n",
        "#     test_error=...\n",
        "    \n",
        "    return train_error, test_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmADqW1v6TTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finish writting the k_fold_cross_validation function. \n",
        "# Returns the average training error and average test error from the k-fold cross validation\n",
        "# Sklearns K-Folds cross-validator: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "\n",
        "def k_fold_cross_validation(k, X, y, alpha):\n",
        "    kf = KFold(n_splits=k, random_state=21, shuffle=True)\n",
        "    total_E_val_test = 0\n",
        "    total_E_val_train = 0\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "        # Centering the data so we do not need the intercept term (we could have also chose w_0=average y value)\n",
        "        # Subtract y_train_mean from y_train and y_test\n",
        "        # y_train_mean = ...\n",
        "        # y_train = ...\n",
        "        # y_test = ...\n",
        "        \n",
        "        # Scaling the data matrix\n",
        "        # Using scaler=preprocessing.StandardScaler().fit(...)\n",
        "        # And scaler.transform(...)\n",
        "        # X_train = \n",
        "        # X_test =\n",
        "        \n",
        "        # Determine the training error and the test error\n",
        "        # Use get_coeff_linear_normaleq or get_coeff_ridge_normaleq to get w\n",
        "        # And use evaluate_err()\n",
        "\n",
        "       ##############\n",
        "    return  total_E_val_test, total_E_val_train\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzqibcos6TTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the error for the both linear regression and ridge regression\n",
        "# the error should include both training error and testing error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_D9GWtE6TTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the model to predict the new test case.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eygbukgG6TT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}