{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "knn.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54vC8oeahG97",
        "colab_type": "text"
      },
      "source": [
        "## Step 1:  Getting, understanding, and cleaning the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6wvgOf9hG98",
        "colab_type": "text"
      },
      "source": [
        "###  Importing the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wUitIlvhG99",
        "colab_type": "code",
        "outputId": "cd768d05-f94d-4962-aa3d-4d1a0d8d21cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Import the usual libraries\n",
        "import matplotlib.pyplot as plt # plotting utilities \n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import math \n",
        "import pandas as pd  # To read in the dataset we will use the Panda's library\n",
        "df = pd.read_csv('iris.csv', header=None, names = [\"sepal length[cm]\",\"sepal width[cm]\",\"petal length[cm]\", \"petal width\", \"label\"])\n",
        "\n",
        "# Next we observe the first 5 rows of the data to ensure everything was read correctly\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length[cm]</th>\n",
              "      <th>sepal width[cm]</th>\n",
              "      <th>petal length[cm]</th>\n",
              "      <th>petal width</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length[cm]  sepal width[cm]  ...  petal width           label\n",
              "145               6.7              3.0  ...          2.3  Iris-virginica\n",
              "146               6.3              2.5  ...          1.9  Iris-virginica\n",
              "147               6.5              3.0  ...          2.0  Iris-virginica\n",
              "148               6.2              3.4  ...          2.3  Iris-virginica\n",
              "149               5.9              3.0  ...          1.8  Iris-virginica\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-3yyHf6hG-D",
        "colab_type": "text"
      },
      "source": [
        "### Data preprocesssing\n",
        "It would be more convenient if the labels were integers instead of 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'.  This way our code can always work with numerical values instead of strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-rk0_3-hG-D",
        "colab_type": "code",
        "outputId": "dba2d077-6989-44d7-b424-a72117960f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df['label'] = df.label.map({'Iris-setosa': 0,\n",
        "              'Iris-versicolor': 1,\n",
        "              'Iris-virginica': 2})\n",
        "df.head()# Again, lets observe the first 5 rows to make sure everything worked before we continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length[cm]</th>\n",
              "      <th>sepal width[cm]</th>\n",
              "      <th>petal length[cm]</th>\n",
              "      <th>petal width</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length[cm]  sepal width[cm]  petal length[cm]  petal width  label\n",
              "0               5.1              3.5               1.4          0.2      0\n",
              "1               4.9              3.0               1.4          0.2      0\n",
              "2               4.7              3.2               1.3          0.2      0\n",
              "3               4.6              3.1               1.5          0.2      0\n",
              "4               5.0              3.6               1.4          0.2      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMS4IXlDhG-G",
        "colab_type": "code",
        "outputId": "fcb4fdb8-51cb-416a-dde3-1e322e60eece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# This time we will use sklearn's method for seperating the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "names = [\"sepal length[cm]\",\"petal width\"]\n",
        "#After completing the assignment, try your code with all the features\n",
        "#names = [\"sepal length[cm]\",\"sepal width[cm]\",\"petal length[cm]\", \"petal width\"]\n",
        "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df[names],df['label'], random_state=0)\n",
        "\n",
        "X_train=df_X_train.to_numpy()\n",
        "X_test=df_X_test.to_numpy()\n",
        "y_train=df_y_train.to_numpy()\n",
        "y_test=df_y_test.to_numpy()\n",
        "\n",
        "#Looking at the train/test split\n",
        "print(\"The number of training examples: \", X_train.shape[0])\n",
        "print(\"The number of test exampels: \", X_test.shape[0])\n",
        "\n",
        "print(\"The first four training labels\")\n",
        "print(y_train[0:4])\n",
        "\n",
        "print(\"The first four iris' measurements\")\n",
        "print(X_test[0:4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of training examples:  112\n",
            "The number of test exampels:  38\n",
            "The first four training labels\n",
            "[1 1 2 0]\n",
            "The first four iris' measurements\n",
            "[[5.8 2.4]\n",
            " [6.  1. ]\n",
            " [5.5 0.2]\n",
            " [7.3 1.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxYkD7ighG-J",
        "colab_type": "text"
      },
      "source": [
        "## visualizing the data set\n",
        "\n",
        "Using a scatter plot to visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdimQzVChG-K",
        "colab_type": "code",
        "outputId": "14cbfce8-cfa3-4d53-ff18-3fbe61f02bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "iris_names=['Iris-setosa','Iris-versicolor','Iris-virginica']\n",
        "for i in range(0,3):\n",
        "    plt.scatter(X_train[y_train == i, 0],\n",
        "                X_train[y_train == i, 1],\n",
        "            marker='o',\n",
        "            label='class '+ str(i)+ ' '+ iris_names[i])\n",
        "\n",
        "plt.xlabel('sepal width[cm]')\n",
        "plt.ylabel('petal length[cm]')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBv-GgAPhG-M",
        "colab_type": "text"
      },
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwdLhxOuhG-N",
        "colab_type": "code",
        "outputId": "1618a34f-69f5-41ba-c1ea-55497bc34aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def euclidean_distance(x1, x2):\n",
        "    #suppose that x1:(1,2) x2:(N*3) \n",
        "    sum_squared = 0\n",
        "    for i in range(len(x2)):\n",
        "      sum_squared += math.pow(x1[i]-x2[i],2)\n",
        "    return math.sqrt(sum_squared)\n",
        "\n",
        "print(euclidean_distance(X_test[0],X_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9055385138137416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v3eiTbXhG-Q",
        "colab_type": "code",
        "outputId": "8e3d9b78-1806-49a7-a27a-f56b8bdc49bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_neighbors( X_train, y_train, x_test, k, distance= euclidean_distance):\n",
        "    # X in N*2, y in N*1, x_test in 2,\n",
        "    # calculate all the distances\n",
        "    # find the nearest K nieghtbors' indexs\n",
        "    # return k nerest negibors\n",
        "\n",
        "    #calculate all the distances between the query and every element in X_train\n",
        "    distances = []\n",
        "    for train in X_train:\n",
        "      distances.append((train,(distance(train,x_test))))\n",
        "    #sort the distances\n",
        "    distances.sort(key=lambda tup: tup[1])\n",
        "\n",
        "    #get the indexes of the distances\n",
        "    knn_indexes = []\n",
        "    knn_labels = []\n",
        "    for nn in range(k):\n",
        "      index = np.where((X_train == distances[nn][0]).all(axis=1))[0][0]\n",
        "      knn_indexes.append(index)\n",
        "      knn_labels.append(y_train[index])\n",
        "\n",
        "    # print(knn_labels)\n",
        "  \n",
        "    \n",
        "\n",
        "    return knn_labels\n",
        "\n",
        "get_neighbors(X_train,y_train,X_test[0],20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYwS7FXJhG-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "def get_label(neighbors_labels):\n",
        "    # calculate and return label with the majority votes\n",
        "    votes = dict( (l, neighbors_labels.count(l) ) for l in set(neighbors_labels))\n",
        "    sorted_votes = sorted(votes.items(), key=lambda x: x[1])\n",
        "    label = sorted_votes[len(sorted_votes)-1][0]\n",
        "    # print(label)\n",
        "\n",
        "\n",
        "    return label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxZpUBzahG-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn(training_data,y_train,testing_data,k,distance= euclidean_distance):\n",
        "    # for each testing data, using functions above to predict the class labes using knn algo\n",
        "    testing_data_labels = []\n",
        "    for query in testing_data:\n",
        "      neighbor_labels = get_neighbors(training_data,y_train,query,k,distance)\n",
        "      query_label = get_label(neighbor_labels)\n",
        "      testing_data_labels.append(query_label)\n",
        "\n",
        "      \n",
        "\n",
        "    return testing_data_labels\n",
        "testing_data_labels = knn(X_train,y_train,X_test,20,distance= euclidean_distance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMid57QFhG-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(y_test,pred):\n",
        "    y_size = len(y_test)\n",
        "    nmc = 0\n",
        "    for i in range(y_size):\n",
        "      if(y_test[i] != pred[i] ):\n",
        "        nmc+=1\n",
        "    \n",
        "    accuracy = (y_size - nmc)/y_size\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B330y--hG-Z",
        "colab_type": "code",
        "outputId": "d46141b0-4bc4-4d5e-d48f-f8a6e29f0334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# K=1\n",
        "testing_data_labels_k1 = knn(X_train,y_train,X_test,1,distance= euclidean_distance)\n",
        "accuracy_k1 = eval(y_test,testing_data_labels_k1 )\n",
        "print(\"Accuracy for K = 1: \",accuracy_k1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for K = 1:  0.9210526315789473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_bZE0lihG-c",
        "colab_type": "code",
        "outputId": "68678144-e107-4dc5-87ee-48f43b004b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# K=3\n",
        "testing_data_labels_k3 = knn(X_train,y_train,X_test,3,distance= euclidean_distance)\n",
        "accuracy_k3 = eval(y_test,testing_data_labels_k3 )\n",
        "print(\"Accuracy for K = 3: \",accuracy_k3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for K = 3:  0.9210526315789473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Pi9B1ShG-f",
        "colab_type": "code",
        "outputId": "a09826ad-2fed-42fc-faa2-3ac5132e5ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# K=5\n",
        "testing_data_labels_k5 = knn(X_train,y_train,X_test,5,distance= euclidean_distance)\n",
        "accuracy_k5 = eval(y_test,testing_data_labels_k5 )\n",
        "print(\"Accuracy for K = 5: \",accuracy_k5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for K = 5:  0.9473684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S54U7ZpIhG-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mydistance(x1, x2):\n",
        "    #Manhattan Distance\n",
        "    difference = 0\n",
        "    for i in range(len(x2)):\n",
        "      difference += abs(x2[i]-x1[i])\n",
        "    return difference\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvlFqYe9hG-k",
        "colab_type": "code",
        "outputId": "06954671-de48-4d54-ce64-b5d6a2a21514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# K=1\n",
        "testing_data_labels_k1 = knn(X_train,y_train,X_test,1,distance= mydistance)\n",
        "accuracy_k1 = eval(y_test,testing_data_labels_k1 )\n",
        "print(\"Accuracy for K = 1 using Manhattan Distance: \",accuracy_k1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for K = 1 using Manhattan Distance:  0.9210526315789473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt-NiDWPhG-m",
        "colab_type": "code",
        "outputId": "e19456b1-1d88-4d85-8d10-44ede9c43a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# K=3\n",
        "testing_data_labels_k3 = knn(X_train,y_train,X_test,3,distance= mydistance)\n",
        "accuracy_k3 = eval(y_test,testing_data_labels_k3 )\n",
        "print(\"Accuracy for K = 3 using Manhattan Distance: \",accuracy_k3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for K = 3 using Manhattan Distance:  0.9210526315789473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5P84nzzhG-p",
        "colab_type": "code",
        "outputId": "0674b2c7-f4e4-4107-b80c-e0d8b33fe3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# K=5\n",
        "testing_data_labels_k5 = knn(X_train,y_train,X_test,5,distance= mydistance)\n",
        "accuracy_k5 = eval(y_test,testing_data_labels_k5 )\n",
        "print(\"Accuracy for K = 5 using Manhattan Distance: \",accuracy_k5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for K = 5 using Manhattan Distance:  0.9473684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BIA5xazmSB2",
        "colab_type": "text"
      },
      "source": [
        "###Resorces \n",
        "- https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n",
        "\n",
        "- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQVjSmRBmk-V",
        "colab_type": "text"
      },
      "source": [
        "- Questions 4,6,7. For k = 1,2,3, which examples were not correctly classified? \n",
        "\n",
        "Those that were really far away from the knn perimeter. As we increased the # of ks, (from 1 to 3), we can see that our accuracy increases as we allow for more neighbors in the perimeter. \n",
        "\n",
        "\n",
        "- Question 10: I choose\n",
        "<a href=\"https://xlinux.nist.gov/dads/HTML/manhattanDistance.html\">Manhattan Distance</a> formula as it is suited for high dimensional data, which I thought might help for data points that are farther away from the knn perimeter. Although it wasnt better, this distance formula proved to be equally perfomant as euclidean distance for this dataset.\n",
        "\n"
      ]
    }
  ]
}